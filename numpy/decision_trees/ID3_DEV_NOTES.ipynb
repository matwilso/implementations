{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Matthew Wilson u0499184\n",
    "## 2018/1/19\n",
    "\n",
    "\n",
    "## HW1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Space\n",
    "---\n",
    "\n",
    "### 1.\n",
    "__(a)__ All possible function in this space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\{\\},\\ \\{\\neg x_1\\},\\ \\{x_1\\},\\ \\{\\neg x_2\\},\\ \\{x_2\\},\\ \\{\\neg x_3\\},\\ \\{x_3\\},\\ \\{\\neg x_4\\},\\ \\{x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2\\},\\ \\{x_1 \\land \\neg x_2\\},\\ \\{\\neg x_1 \\land x_2\\},\\ \\{x_1 \\land x_2\\},\\ \\{\\neg x_1 \\land \\neg x_3\\},\\ \\{x_1 \\land \\neg x_3\\},\\ \\{\\neg x_1 \\land x_3\\},\\ \\{x_1 \\land x_3\\},\\ \\{\\neg x_1 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land x_4\\},\\ \\{x_1 \\land x_4\\},\\ \\{\\neg x_2 \\land \\neg x_3\\},\\ \\{x_2 \\land \\neg x_3\\},\\ \\{\\neg x_2 \\land x_3\\},\\ \\{x_2 \\land x_3\\},\\ \\{\\neg x_2 \\land \\neg x_4\\},\\ \\{x_2 \\land \\neg x_4\\},\\ \\{\\neg x_2 \\land x_4\\},\\ \\{x_2 \\land x_4\\},\\ \\{\\neg x_3 \\land \\neg x_4\\},\\ \\{x_3 \\land \\neg x_4\\},\\ \\{\\neg x_3 \\land x_4\\},\\ \\{x_3 \\land x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land \\neg x_3\\},\\ \\{x_1 \\land \\neg x_2 \\land \\neg x_3\\},\\ \\{\\neg x_1 \\land x_2 \\land \\neg x_3\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land x_3\\},\\ \\{x_1 \\land x_2 \\land \\neg x_3\\},\\ \\{x_1 \\land \\neg x_2 \\land x_3\\},\\ \\{\\neg x_1 \\land x_2 \\land x_3\\},\\ \\{x_1 \\land x_2 \\land x_3\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land x_2 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land x_4\\},\\ \\{x_1 \\land x_2 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land x_4\\},\\ \\{\\neg x_1 \\land x_2 \\land x_4\\},\\ \\{x_1 \\land x_2 \\land x_4\\},\\ \\{\\neg x_1 \\land \\neg x_3 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_3 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land x_3 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land \\neg x_3 \\land x_4\\},\\ \\{x_1 \\land x_3 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_3 \\land x_4\\},\\ \\{\\neg x_1 \\land x_3 \\land x_4\\},\\ \\{x_1 \\land x_3 \\land x_4\\},\\ \\{\\neg x_2 \\land \\neg x_3 \\land \\neg x_4\\},\\ \\{x_2 \\land \\neg x_3 \\land \\neg x_4\\},\\ \\{\\neg x_2 \\land x_3 \\land \\neg x_4\\},\\ \\{\\neg x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{x_2 \\land x_3 \\land \\neg x_4\\},\\ \\{x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{\\neg x_2 \\land x_3 \\land x_4\\},\\ \\{x_2 \\land x_3 \\land x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land \\neg x_3 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land \\neg x_3 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land x_2 \\land \\neg x_3 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land x_3 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{x_1 \\land x_2 \\land \\neg x_3 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land x_3 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{\\neg x_1 \\land x_2 \\land x_3 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land x_3 \\land x_4\\},\\ \\{x_1 \\land x_2 \\land x_3 \\land \\neg x_4\\},\\ \\{x_1 \\land x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land x_3 \\land x_4\\},\\ \\{\\neg x_1 \\land x_2 \\land x_3 \\land x_4\\},\\ \\{x_1 \\land x_2 \\land x_3 \\land x_4\\}$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "from itertools import *\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "equations = []\n",
    "pos = ['x_1', 'x_2', 'x_3', 'x_4']\n",
    "powset = powerset(pos)\n",
    "count = 0\n",
    "for p in powset:\n",
    "    #print(p)\n",
    "    #neg = tuple([r'\\neg '+x for x in p])\n",
    "    #print(neg)\n",
    "    subpowset = powerset(p)\n",
    "    \n",
    "    for s in subpowset:\n",
    "        equation = []\n",
    "        for var in p:\n",
    "            pos_or_neg = var if var in s else r'\\neg '+var \n",
    "            equation.append(pos_or_neg)\n",
    "        count += 1\n",
    "        equations.append('\\{'+' \\land '.join(equation)+'\\}')\n",
    "display(Math(',\\ '.join(equations)))\n",
    "    \n",
    "    #negs = r' \\land '.join(neg)\n",
    "    #ps = r' \\land '.join(p)\n",
    "    #print(r'$$'+negs+'$$')\n",
    "    #print(r'$$'+ps+'$$')    \n",
    "    #display(Math(negs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b)__ All functions consistent with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\{x_1 \\land \\neg x_2\\},\\ \\{x_1 \\land x_3\\},\\ \\{x_1 \\land x_4\\},\\ \\{\\neg x_2 \\land x_4\\},\\ \\{x_3 \\land x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land \\neg x_3\\},\\ \\{x_1 \\land \\neg x_2 \\land x_3\\},\\ \\{x_1 \\land x_2 \\land x_3\\},\\ \\{x_1 \\land \\neg x_2 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land x_4\\},\\ \\{x_1 \\land x_2 \\land x_4\\},\\ \\{x_1 \\land x_3 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_3 \\land x_4\\},\\ \\{\\neg x_1 \\land x_3 \\land x_4\\},\\ \\{x_1 \\land x_3 \\land x_4\\},\\ \\{\\neg x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{\\neg x_2 \\land x_3 \\land x_4\\},\\ \\{x_2 \\land x_3 \\land x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land \\neg x_3 \\land \\neg x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land x_3 \\land \\neg x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{\\neg x_1 \\land \\neg x_2 \\land x_3 \\land x_4\\},\\ \\{x_1 \\land x_2 \\land x_3 \\land \\neg x_4\\},\\ \\{x_1 \\land x_2 \\land \\neg x_3 \\land x_4\\},\\ \\{x_1 \\land \\neg x_2 \\land x_3 \\land x_4\\},\\ \\{\\neg x_1 \\land x_2 \\land x_3 \\land x_4\\},\\ \\{x_1 \\land x_2 \\land x_3 \\land x_4\\}$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from itertools import *\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "God, this was a pain in the ass to write.  I think I was just thinking about it wrong at first.\n",
    "I should have worked it out a bit more and modularized components more before diving in.\n",
    "\n",
    "But yay, I am so glad to have it done. I am also glad that I didn't do it by hand.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "data = np.array([\n",
    "[0, 0, 1, 0],\n",
    "[0, 1, 0, 0], \n",
    "[0, 0, 1, 1], \n",
    "[1, 0, 0, 1], \n",
    "[0, 1, 1, 0], \n",
    "[1, 1, 0, 0], \n",
    "[0, 1, 0, 1]  \n",
    "], dtype=np.int8)\n",
    "labels = [0, 0, 1, 1, 0, 0, 0]\n",
    "\n",
    "x_vec = ['x_1', 'x_2', 'x_3', 'x_4']\n",
    "powset = powerset(x_vec)\n",
    "count = 0\n",
    "equations = []\n",
    "for p in powset:\n",
    "    #print(p)\n",
    "    #neg = tuple([r'\\neg '+x for x in p])\n",
    "    #print(neg)\n",
    "    subpowset = powerset(p)\n",
    "    \n",
    "    #print(subpowset)\n",
    "    \n",
    "    \n",
    "    for s in subpowset:\n",
    "        equation = []\n",
    "        evals = [None, None, None, None]\n",
    "        \n",
    "        #print(s)\n",
    "        \n",
    "        if s == ():\n",
    "            continue\n",
    "            \n",
    "        for i,var in enumerate(p):\n",
    "            #print(var)\n",
    "            if var in s:\n",
    "                evals[x_vec.index(var)] = \"and\"\n",
    "                pos_or_neg = var \n",
    "            else:\n",
    "                pos_or_neg = r'\\neg '+var \n",
    "                evals[x_vec.index(var)] = \"not\"\n",
    "            \n",
    "            equation.append(pos_or_neg)\n",
    "            \n",
    "        fits_data = True\n",
    "        for i in range(data.shape[0]):\n",
    "            data_pt = data[i]\n",
    "            #print(data_pt)\n",
    "            #print(evals)\n",
    "            final_truth = True\n",
    "            for j in range(data_pt.shape[0]):\n",
    "                pt_pt = data_pt[j]\n",
    "                #print(pt_pt, final_truth)\n",
    "                if evals[j] == \"and\":\n",
    "                    final_truth = final_truth and pt_pt\n",
    "                elif evals[j] == \"not\":\n",
    "                    final_truth = final_truth and not pt_pt\n",
    "                    \n",
    "            if final_truth == 1:\n",
    "                fits_data = fits_data and final_truth == labels[i]\n",
    "            #print('fits dat', fits_data, ' label = ', labels[i])\n",
    "        if fits_data:\n",
    "            equations.append('\\{'+' \\land '.join(equation)+'\\}')\n",
    "            #display(Math(' \\land '.join(equation)))\n",
    "            \n",
    "display(Math(',\\ '.join(equations)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c__. 3^n-1\n",
    "\n",
    "__d__. 3^n-1. The conjunction of a set of binary values, including their negations, can represent any boolean function.  This is again assuming that not all functions must depend on all variables, as alluded to in the problem statement example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "---\n",
    "__(a)__  All possible functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "At least m = [0] of the subset n = $\\{x_1\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0] of the subset n = $\\{x_2\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0] of the subset n = $\\{x_3\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0] of the subset n = $\\{x_4\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1] of the subset n = $\\{x_1,x_2\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1] of the subset n = $\\{x_1,x_3\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1] of the subset n = $\\{x_1,x_4\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1] of the subset n = $\\{x_2,x_3\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1] of the subset n = $\\{x_2,x_4\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1] of the subset n = $\\{x_3,x_4\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1, 2] of the subset n = $\\{x_1,x_2,x_3\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1, 2] of the subset n = $\\{x_1,x_2,x_4\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1, 2] of the subset n = $\\{x_1,x_3,x_4\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1, 2] of the subset n = $\\{x_2,x_3,x_4\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [0, 1, 2, 3] of the subset n = $\\{x_1,x_2,x_3,x_4\\}$ values must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "from itertools import *\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "pos = ['x_1', 'x_2', 'x_3', 'x_4']\n",
    "powset = powerset(pos)\n",
    "count = 0\n",
    "\n",
    "for p in powset[1:]:\n",
    "    display(Latex('At least m = {} of the subset n = ${}$ values must be 1'.format(list(range(len(p))), r'\\{'+','.join(p)+r'\\}')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b)__ Those that fit the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import *\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "data = np.array([\n",
    "[0, 0, 1, 0],\n",
    "[0, 1, 0, 0], \n",
    "[0, 0, 1, 1], \n",
    "[1, 0, 0, 1], \n",
    "[0, 1, 1, 0], \n",
    "[1, 1, 0, 0], \n",
    "[0, 1, 0, 1]  \n",
    "], dtype=np.int8)\n",
    "labels = np.array([0, 0, 1, 1, 0, 0, 0])\n",
    "\n",
    "x_vec = ['x_1', 'x_2', 'x_3', 'x_4']\n",
    "\n",
    "powset = powerset(pos)\n",
    "count = 0\n",
    "\n",
    "def check(subset):\n",
    "    indices = [x_vec.index(x) for x in subset]\n",
    "    \n",
    "    pos_counts = range(len(subset)+1)\n",
    "    final_pos = []\n",
    "    \n",
    "    for i in pos_counts:\n",
    "        fits_data = True\n",
    "        for j in range(data.shape[0]):\n",
    "            #if labels[j] == 1:\n",
    "            #    fits_data = fits_data and np.count_nonzero(data[j][indices]) >= i\n",
    "            #else:\n",
    "            if labels[j] == 0:\n",
    "                fits_data = fits_data and np.count_nonzero(data[j][indices]) < i\n",
    "            #print(i, j, fits_data, np.count_nonzero(data[j][indices]))\n",
    "            \n",
    "        if fits_data:\n",
    "            final_pos.append(i)\n",
    "            \n",
    "    return final_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "At least m = [2] of the values $\\{x_1,x_3\\}$ must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [2] of the values $\\{x_1,x_4\\}$ must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [2] of the values $\\{x_3,x_4\\}$ must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [3] of the values $\\{x_1,x_2,x_3\\}$ must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [3] of the values $\\{x_1,x_2,x_4\\}$ must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [2, 3] of the values $\\{x_1,x_3,x_4\\}$ must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [3] of the values $\\{x_2,x_3,x_4\\}$ must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "At least m = [3, 4] of the values $\\{x_1,x_2,x_3,x_4\\}$ must be 1"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for p in powset[1:]:\n",
    "    l = check(p)\n",
    "    if l != []:\n",
    "        display(Latex('At least m = {} of the values ${}$ must be 1'.format(l, r'\\{'+','.join(p)+r'\\}')))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(c)__ There are $\\Sigma^n_{k=0} (^n_k)(k+1)$ possibilities, where n is the number of binary features\n",
    "\n",
    "\n",
    "__(d)__ Conjunction space can represent any Boolean logic, so is fully expressive. \n",
    "m of n is less expressive. It cannot create a function that includes $\\{x_1,\\neg x_2, x_3, x_4\\}$, but doesn't include $\\{x_1, x_2, x_3, x_4\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "\n",
    "### 1\n",
    "\n",
    "__(a)__\n",
    "\n",
    "ID3 Root \n",
    "\n",
    "1. First, compute the baseline root entropy. The labels are [0,0,1,1,0,0,0], so 2/7 positive and 5/7 negative.  The entropy $H$ of this is $\\sum_{i=1}^K p_ilog(p_i) = 0.86312$\n",
    "1. Next compute the expected entropies for each of the columns of data $\\{x_1, x_2, x_3, x_4\\}$, using the positive and negative labels. So, compute entropies for each possible value (e.g., x1 = 0 or 1), then do a weighted average based on the probabilities of these (Expectation).\n",
    "1. Once I have the expected entropy, I compute the information gain as root entropy - expected entropy.  See computations below.\n",
    "1. Then I choose to split on whatever column has the highest information gain. There is a tie between x2 and x4 at 0.469, so I arbitrarily choose either one. I will choose x2. Follow the steps below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root entropy\n",
      "Entropy = 0.863120568566631\n",
      "------------------------------\n",
      "COLUMN = x1\n",
      "[x1 = 0]\n",
      "Probability = 0.7142857142857143\n",
      "Entropy = 0.7219280948873623\n",
      "[x1 = 1]\n",
      "Probability = 0.2857142857142857\n",
      "Entropy = 1.0\n",
      "\n",
      "Expected Entropy = 0.8013772106338303\n",
      "\n",
      "INFORMATION GAIN = 0.061743357932800724\n",
      "------------------------------\n",
      "\n",
      "COLUMN = x2\n",
      "[x2 = 0]\n",
      "Probability = 0.42857142857142855\n",
      "Entropy = 0.9182958340544896\n",
      "[x2 = 1]\n",
      "Probability = 0.5714285714285714\n",
      "Entropy = -0.0\n",
      "\n",
      "Expected Entropy = 0.39355535745192405\n",
      "\n",
      "INFORMATION GAIN = 0.46956521111470695\n",
      "------------------------------\n",
      "\n",
      "COLUMN = x3\n",
      "[x3 = 0]\n",
      "Probability = 0.5714285714285714\n",
      "Entropy = 0.8112781244591328\n",
      "[x3 = 1]\n",
      "Probability = 0.42857142857142855\n",
      "Entropy = 0.9182958340544896\n",
      "\n",
      "Expected Entropy = 0.8571428571428571\n",
      "\n",
      "INFORMATION GAIN = 0.0059777114237739015\n",
      "------------------------------\n",
      "\n",
      "COLUMN = x4\n",
      "[x4 = 0]\n",
      "Probability = 0.5714285714285714\n",
      "Entropy = -0.0\n",
      "[x4 = 1]\n",
      "Probability = 0.42857142857142855\n",
      "Entropy = 0.9182958340544896\n",
      "\n",
      "Expected Entropy = 0.39355535745192405\n",
      "\n",
      "INFORMATION GAIN = 0.46956521111470695\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_entropy(cat, verbose=False):\n",
    "    num_tot = (cat.shape[0])\n",
    "    category_probs = []\n",
    "    for c in set(cat):\n",
    "        num_match = np.count_nonzero(cat == c)\n",
    "        category_probs.append(num_match / num_tot)\n",
    "        if verbose:\n",
    "            print(\"Num match = {}, Total = {}\".format(num_match, num_tot))\n",
    "    entropy = -np.sum(category_probs * np.log2(category_probs))\n",
    "    return entropy\n",
    "\n",
    "def calculate_expected_entropy(cat, labels, verbose=False):\n",
    "    \"\"\"Calculate the expected entropy for a column of data\"\"\"\n",
    "    tot_expected = 0\n",
    "    for c in set(cat):\n",
    "        prob_of_c = labels[cat == c].shape[0] / labels.shape[0]\n",
    "        ind_ent = calculate_entropy(labels[cat == c])\n",
    "        if verbose:\n",
    "            print(\"[{} = {}]\".format(name, c))\n",
    "            print(\"Probability = {}\".format(prob_of_c))\n",
    "            print(\"Entropy = {}\".format(ind_ent))\n",
    "        tot_expected += prob_of_c * ind_ent\n",
    "    return tot_expected\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Root entropy\")\n",
    "\n",
    "root_ent = calculate_entropy(labels)\n",
    "print(\"Entropy = {}\".format(root_ent))\n",
    "print('-'*30)\n",
    "\n",
    "ees = np.zeros_like(x_vec, dtype=np.float64)\n",
    "for i in range(4):\n",
    "    x = data[:,i]\n",
    "    name = \"x\"+str(i+1)\n",
    "    print(\"COLUMN = \"+name)\n",
    "    ee = calculate_expected_entropy(x, labels, name)\n",
    "    ees[i] = ee\n",
    "    print()\n",
    "    print(\"Expected Entropy = {}\".format(ee))\n",
    "    ig = root_ent - ee\n",
    "    print()\n",
    "    print(\"INFORMATION GAIN = {}\".format(ig))\n",
    "    print('-'*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3 1st level\n",
    "\n",
    "1. We chose to split on x2, so now we consider both branches of x2 (x2 = 0, x2 = 1).\n",
    "2. Notice that x2 = 1 has 0 entropy because it always produces y = 0.  This branch side is considered done.\n",
    "3. Now we compute the information gains in the same fashion as the root branch.  Computations are below.\n",
    "4. x4 now has the highest information gain, so we choose it to branch on next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When (x_2 = 0)\n",
      "Labels = [0 1 1]\n",
      "Branch Entropy = 0.9182958340544896\n",
      "\n",
      "------------------------------\n",
      "COLUMN = x1\n",
      "[x1 = 0]\n",
      "Probability = 0.6666666666666666\n",
      "Entropy = 1.0\n",
      "[x1 = 1]\n",
      "Probability = 0.3333333333333333\n",
      "Entropy = -0.0\n",
      "\n",
      "Expected Entropy = 0.6666666666666666\n",
      "\n",
      "INFORMATION GAIN = 0.2516291673878229\n",
      "------------------------------\n",
      "\n",
      "COLUMN = x3\n",
      "[x3 = 0]\n",
      "Probability = 0.3333333333333333\n",
      "Entropy = -0.0\n",
      "[x3 = 1]\n",
      "Probability = 0.6666666666666666\n",
      "Entropy = 1.0\n",
      "\n",
      "Expected Entropy = 0.6666666666666666\n",
      "\n",
      "INFORMATION GAIN = 0.2516291673878229\n",
      "------------------------------\n",
      "\n",
      "COLUMN = x4\n",
      "[x4 = 0]\n",
      "Probability = 0.3333333333333333\n",
      "Entropy = -0.0\n",
      "[x4 = 1]\n",
      "Probability = 0.6666666666666666\n",
      "Entropy = -0.0\n",
      "\n",
      "Expected Entropy = 0.0\n",
      "\n",
      "INFORMATION GAIN = 0.9182958340544896\n",
      "------------------------------\n",
      "\n",
      "When (x_2 = 1)\n",
      "Labels = [0 0 0 0]\n",
      "Branch Entropy = -0.0\n",
      "\n",
      "ENTROPY IS 0, SO THIS BRANCH IS SOLVED\n"
     ]
    }
   ],
   "source": [
    "split = np.argmin(ees) \n",
    "split_column = data[:, split]\n",
    "\n",
    "for b in set(data[:, split]):\n",
    "    print(\"When ({} = {})\".format(x_vec[split], b))\n",
    "    data_split = data[split_column == b]\n",
    "    label_split = labels[split_column == b]\n",
    "    print(\"Labels = {}\".format(label_split))\n",
    "    branch_ent = calculate_entropy(label_split)\n",
    "    print(\"Branch Entropy = {}\".format(branch_ent))\n",
    "    print()\n",
    "    if np.isclose(branch_ent, 0.0):\n",
    "        print(\"ENTROPY IS 0, SO THIS BRANCH IS SOLVED\")\n",
    "        continue\n",
    "        \n",
    "    print('-'*30)\n",
    "        \n",
    "    for i in range(4):\n",
    "        if i == split:\n",
    "            continue\n",
    "        x = data_split[:,i]\n",
    "        name = \"x\"+str(i+1)\n",
    "        print(\"COLUMN = \"+name)\n",
    "        ee = calculate_expected_entropy(x, label_split, name)\n",
    "        print()\n",
    "        print(\"Expected Entropy = {}\".format(ee))\n",
    "        ig = branch_ent - ee\n",
    "        print()\n",
    "        print(\"INFORMATION GAIN = {}\".format(ig))\n",
    "        print('-'*30)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print(\"Branch entropy\")\n",
    "##branch_ent = ees[split]\n",
    "##print(\"Entropy = {}\".format(root_ent))\n",
    "##print('-'*30)\n",
    "##for i in range(4):\n",
    "##    if i == split:\n",
    "##        continue\n",
    "##    x = data[:,i]\n",
    "##    name = \"x\"+str(i+1)\n",
    "##    print(\"COLUMN = \"+name)\n",
    "##    ee = calculate_expected_entropy(x, labels, name)\n",
    "##    print()\n",
    "##    print(\"Expected Entropy = {}\".format(ee))\n",
    "##    ig = branch_ent - ee\n",
    "##    print()\n",
    "##    print(\"INFORMATION GAIN = {}\".format(ig))\n",
    "##    print('-'*30)\n",
    "##    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3 2nd level\n",
    "\n",
    "1. We find that x4 has 0 entropy, and so we notice that it completely splits the remaining data points.  When it is 1, the y-value is always 1.  Thus we branch on x4, and we have the final decision tree.\n",
    "\n",
    "<img src=\"decision_tree.png\" width=\"500px\"/>\n",
    "\n",
    "\n",
    "__(b)__. $\\neg x_2 \\land x_4$\n",
    "\n",
    "\n",
    "$x_1$ | $x_2$ | $x_3$ | $x_4$ | $y = \\neg x_2 \\land x_4$\n",
    "--- | --- | --- | --- | ---\n",
    "0 | 0 | 0 | 0 | 0  \n",
    "0 | 0 | 0 | 1 | 1  \n",
    "0 | 0 | 1 | 0 | 0  \n",
    "0 | 0 | 1 | 1 | 1  \n",
    "0 | 1 | 0 | 0 | 0  \n",
    "0 | 1 | 0 | 1 | 0  \n",
    "0 | 1 | 1 | 0 | 0  \n",
    "0 | 1 | 1 | 1 | 0  \n",
    "1 | 0 | 0 | 0 | 0  \n",
    "1 | 0 | 0 | 1 | 1  \n",
    "1 | 0 | 1 | 0 | 0  \n",
    "1 | 0 | 1 | 1 | 0  \n",
    "1 | 1 | 0 | 0 | 0  \n",
    "1 | 1 | 0 | 1 | 0  \n",
    "1 | 1 | 1 | 0 | 0  \n",
    "1 | 1 | 1 | 1 | 0  \n",
    "\n",
    "__(c)__.  The ID3 algorithm is much better at searching through the hypothesis space than just brute forcing.  The most important step is the entropy calculations because that allows us to figure out the most important features that contribute to the final boolean function.  For each step, on average, we are able to split the remaining boolean functions to search through in half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape</th>\n",
       "      <th>color</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>circle</td>\n",
       "      <td>blue</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>circle</td>\n",
       "      <td>blue</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>circle</td>\n",
       "      <td>red</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>circle</td>\n",
       "      <td>red</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>circle</td>\n",
       "      <td>green</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>circle</td>\n",
       "      <td>green</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>square</td>\n",
       "      <td>blue</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>square</td>\n",
       "      <td>green</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>square</td>\n",
       "      <td>green</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>square</td>\n",
       "      <td>red</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>triangle</td>\n",
       "      <td>blue</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>triangle</td>\n",
       "      <td>blue</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shape  color label\n",
       "0     circle   blue     c\n",
       "1     circle   blue     c\n",
       "2     circle    red     b\n",
       "3     circle    red     b\n",
       "4     circle  green     a\n",
       "5     circle  green     a\n",
       "6     square   blue     a\n",
       "7     square  green     b\n",
       "8     square  green     b\n",
       "9     square    red     b\n",
       "10  triangle   blue     b\n",
       "11  triangle   blue     b"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "shape_df = pd.read_csv('shapes.csv')\n",
    "display(shape_df)\n",
    "\n",
    "shapes = shape_df.values[:,:-1]\n",
    "shape_names = shape_df.columns[:-1]\n",
    "labels = shape_df.values[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__ I follow the exact same process as in Part 1, extended to support more classes\n",
    "\n",
    "ID3 Root \n",
    "1. First, compute the baseline root entropy. The labels are [c,c,b,b,a,a,a,b,b,b,b,b], so 3/12 a and 7/12 b and 2/12 c.  The entropy $H$ of this is $\\sum_{i=1}^K p_ilog(p_i) = 1.384$\n",
    "1. Next compute the expected entropies for each of the columns of data {shape, color}, using the abc labels. So, compute entropies for each possible value (e.g., shape = red or blue or green), then do a weighted average based on the probabilities of these (Expectation).\n",
    "1. Once I have the expected entropy, I compute the information gain as (root entropy - expected entropy).  See computations below.\n",
    "1. Then I choose to split on whatever column has the highest information gain. Color has the highest information gain, so that is what I split on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root entropy\n",
      "Entropy = 1.384431504340598\n",
      "------------------------------\n",
      "COLUMN = shape\n",
      "\n",
      "[shape = square]\n",
      "Probability = 0.3333333333333333\n",
      "Entropy = 0.8112781244591328\n",
      "[shape = triangle]\n",
      "Probability = 0.16666666666666666\n",
      "Entropy = -0.0\n",
      "[shape = circle]\n",
      "Probability = 0.5\n",
      "Entropy = 1.584962500721156\n",
      "\n",
      "Expected Entropy = 1.0629072918469555\n",
      "\n",
      "INFORMATION GAIN = 0.3215242124936424\n",
      "------------------------------\n",
      "\n",
      "COLUMN = color\n",
      "\n",
      "[color = red]\n",
      "Probability = 0.25\n",
      "Entropy = -0.0\n",
      "[color = blue]\n",
      "Probability = 0.4166666666666667\n",
      "Entropy = 1.5219280948873621\n",
      "[color = green]\n",
      "Probability = 0.3333333333333333\n",
      "Entropy = 1.0\n",
      "\n",
      "Expected Entropy = 0.9674700395364009\n",
      "\n",
      "INFORMATION GAIN = 0.41696146480419705\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Root entropy\")\n",
    "root_ent = calculate_entropy(labels)\n",
    "print(\"Entropy = {}\".format(root_ent))\n",
    "print('-'*30)\n",
    "\n",
    "ees = np.zeros_like(shape_df.columns[:-1], dtype=np.float64)\n",
    "for i in range(2):\n",
    "    x = shapes[:,i]\n",
    "    name = shape_names[i]\n",
    "    print(\"COLUMN = {}\".format(name))\n",
    "    print()\n",
    "    ee = calculate_expected_entropy(x, labels, name)\n",
    "    ees[i] = ee\n",
    "    print()\n",
    "    print(\"Expected Entropy = {}\".format(ee))\n",
    "    ig = root_ent - ee\n",
    "    print()\n",
    "    print(\"INFORMATION GAIN = {}\".format(ig))\n",
    "    print('-'*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3 1st level branching\n",
    "\n",
    "\n",
    "1. We chose to split on color, so now we consider all branches of color (color = red, color = green, color = blue).\n",
    "1. Obviously we only have shape left to split, but we show the branch calculations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WHEN (COLOR = RED)\n",
      "Labels = ['b' 'b' 'b']\n",
      "Branch Entropy = -0.0\n",
      "\n",
      "ENTROPY IS 0, SO THIS BRANCH IS SOLVED\n",
      "------------------------------\n",
      "\n",
      "WHEN (COLOR = BLUE)\n",
      "Labels = ['c' 'c' 'a' 'b' 'b']\n",
      "Branch Entropy = 1.5219280948873621\n",
      "\n",
      "------------------------------\n",
      "COLUMN = shape\n",
      "['circle' 'circle' 'square' 'triangle' 'triangle']\n",
      "[shape = square]\n",
      "Probability = 0.2\n",
      "Entropy = -0.0\n",
      "[shape = triangle]\n",
      "Probability = 0.4\n",
      "Entropy = -0.0\n",
      "[shape = circle]\n",
      "Probability = 0.4\n",
      "Entropy = -0.0\n",
      "\n",
      "Expected Entropy = 0.0\n",
      "\n",
      "INFORMATION GAIN = 1.5219280948873621\n",
      "------------------------------\n",
      "\n",
      "\n",
      "WHEN (COLOR = GREEN)\n",
      "Labels = ['a' 'a' 'b' 'b']\n",
      "Branch Entropy = 1.0\n",
      "\n",
      "------------------------------\n",
      "COLUMN = shape\n",
      "['circle' 'circle' 'square' 'square']\n",
      "[shape = square]\n",
      "Probability = 0.5\n",
      "Entropy = -0.0\n",
      "[shape = circle]\n",
      "Probability = 0.5\n",
      "Entropy = -0.0\n",
      "\n",
      "Expected Entropy = 0.0\n",
      "\n",
      "INFORMATION GAIN = 1.0\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split = np.argmin(ees) \n",
    "split_column = shapes[:, split]\n",
    "\n",
    "for b in set(shapes[:, split]):\n",
    "    print()\n",
    "    print(\"When ({} = {})\".format(shape_names[split], b).upper())\n",
    "    data_split = shapes[split_column == b]\n",
    "    label_split = labels[split_column == b]\n",
    "    print(\"Labels = {}\".format(label_split))\n",
    "    branch_ent = calculate_entropy(label_split)\n",
    "    print(\"Branch Entropy = {}\".format(branch_ent))\n",
    "    print()\n",
    "    if np.isclose(branch_ent, 0.0):\n",
    "        print(\"ENTROPY IS 0, SO THIS BRANCH IS SOLVED\")\n",
    "        print('-'*30)\n",
    "        continue\n",
    "        \n",
    "    print('-'*30)\n",
    "        \n",
    "    for i in range(2):\n",
    "        if i == split:\n",
    "            continue\n",
    "        x = data_split[:,i]\n",
    "        name = shape_names[i]\n",
    "        print(\"COLUMN = {}\".format(name))\n",
    "        print(x)\n",
    "        ee = calculate_expected_entropy(x, label_split, name)\n",
    "        print()\n",
    "        print(\"Expected Entropy = {}\".format(ee))\n",
    "        ig = branch_ent - ee\n",
    "        print()\n",
    "        print(\"INFORMATION GAIN = {}\".format(ig))\n",
    "        print('-'*30)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"shape_tree.png\" width=\"500px\"/>\n",
    "\n",
    "__(b)__ For a new Green Triangle, the decision tree would sort it by its green color, then since no triangles were trained on, and the only possible labels for Green things are A or B, it would choose either one of these labels arbritrarily (maybe 50/50).\n",
    "\n",
    "__(c)__ Mine is the same as example tree.  It can predict it because I gave it a rule for how to label unknown items for this type of case. I guess the example tree didn't make a rule for this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>strong</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>strong</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rainy</td>\n",
       "      <td>medium</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sunny</td>\n",
       "      <td>medium</td>\n",
       "      <td>normal</td>\n",
       "      <td>strong</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rainy</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlook Temperature Humidity    Wind Play\n",
       "0      sunny         hot     high    weak    -\n",
       "1      sunny         hot     high  strong    -\n",
       "2   overcast         hot     high    weak    +\n",
       "3      rainy      medium     high    weak    +\n",
       "4      rainy        cool   normal    weak    +\n",
       "5      rainy        cool   normal  strong    -\n",
       "6   overcast        cool   normal  strong    +\n",
       "7      sunny      medium     high    weak    -\n",
       "8      sunny        cool   normal    weak    +\n",
       "9      rainy      medium   normal    weak    +\n",
       "10     sunny      medium   normal  strong    +\n",
       "11  overcast      medium     high  strong    +\n",
       "12  overcast         hot   normal    weak    +\n",
       "13     rainy      medium     high  strong    -\n",
       "14       NaN      medium     high  strong    -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tennis_df = pd.read_csv('tennis.csv')\n",
    "display(tennis_df)\n",
    "\n",
    "values = tennis_df.values[:,:-1]\n",
    "labels = tennis_df.values[:,-1]\n",
    "cat_names = tennis_df.columns[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__ Missing Outlook = sunny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root entropy\n",
      "Entropy = 0.9709505944546686\n",
      "------------------------------\n",
      "COLUMN = Outlook\n",
      "\n",
      "[Outlook = rainy]\n",
      "Probability = 0.3333333333333333\n",
      "Entropy = 0.9709505944546686\n",
      "[Outlook = overcast]\n",
      "Probability = 0.26666666666666666\n",
      "Entropy = -0.0\n",
      "[Outlook = sunny]\n",
      "Probability = 0.4\n",
      "Entropy = 0.9182958340544896\n",
      "\n",
      "Expected Entropy = 0.690968531773352\n",
      "\n",
      "INFORMATION GAIN = 0.27998206268131653\n",
      "------------------------------\n",
      "\n",
      "COLUMN = Temperature\n",
      "\n",
      "[Temperature = hot]\n",
      "Probability = 0.26666666666666666\n",
      "Entropy = 1.0\n",
      "[Temperature = cool]\n",
      "Probability = 0.26666666666666666\n",
      "Entropy = 0.8112781244591328\n",
      "[Temperature = medium]\n",
      "Probability = 0.4666666666666667\n",
      "Entropy = 0.9852281360342515\n",
      "\n",
      "Expected Entropy = 0.942780630005086\n",
      "\n",
      "INFORMATION GAIN = 0.02816996444958253\n",
      "------------------------------\n",
      "\n",
      "COLUMN = Humidity\n",
      "\n",
      "[Humidity = high]\n",
      "Probability = 0.5333333333333333\n",
      "Entropy = 0.9544340029249649\n",
      "[Humidity = normal]\n",
      "Probability = 0.4666666666666667\n",
      "Entropy = 0.5916727785823275\n",
      "\n",
      "Expected Entropy = 0.7851454315650674\n",
      "\n",
      "INFORMATION GAIN = 0.18580516288960114\n",
      "------------------------------\n",
      "\n",
      "COLUMN = Wind\n",
      "\n",
      "[Wind = strong]\n",
      "Probability = 0.4666666666666667\n",
      "Entropy = 0.9852281360342515\n",
      "[Wind = weak]\n",
      "Probability = 0.5333333333333333\n",
      "Entropy = 0.8112781244591328\n",
      "\n",
      "Expected Entropy = 0.8924547965275216\n",
      "\n",
      "INFORMATION GAIN = 0.078495797927147\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Root entropy\")\n",
    "root_ent = calculate_entropy(labels)\n",
    "print(\"Entropy = {}\".format(root_ent))\n",
    "print('-'*30)\n",
    "values[-1,0] = 'sunny'\n",
    "\n",
    "ees = np.zeros_like(cat_names, dtype=np.float64)\n",
    "for i in range(len(cat_names)):\n",
    "    x = values[:,i]\n",
    "    name = cat_names[i]\n",
    "    print(\"COLUMN = {}\".format(name))\n",
    "    print()\n",
    "    ee = calculate_expected_entropy(x, labels, name)\n",
    "    ees[i] = ee\n",
    "    print()\n",
    "    print(\"Expected Entropy = {}\".format(ee))\n",
    "    ig = root_ent - ee\n",
    "    print()\n",
    "    print(\"INFORMATION GAIN = {}\".format(ig))\n",
    "    print('-'*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b)__ Missing Outlook = overcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root entropy\n",
      "Entropy = 0.9709505944546686\n",
      "------------------------------\n",
      "COLUMN = Outlook\n",
      "\n",
      "[Outlook = rainy]\n",
      "Probability = 0.3333333333333333\n",
      "Entropy = 0.9709505944546686\n",
      "[Outlook = overcast]\n",
      "Probability = 0.3333333333333333\n",
      "Entropy = 0.7219280948873623\n",
      "[Outlook = sunny]\n",
      "Probability = 0.3333333333333333\n",
      "Entropy = 0.9709505944546686\n",
      "\n",
      "Expected Entropy = 0.8879430945988998\n",
      "\n",
      "INFORMATION GAIN = 0.08300749985576883\n",
      "------------------------------\n",
      "\n",
      "COLUMN = Temperature\n",
      "\n",
      "[Temperature = hot]\n",
      "Probability = 0.26666666666666666\n",
      "Entropy = 1.0\n",
      "[Temperature = cool]\n",
      "Probability = 0.26666666666666666\n",
      "Entropy = 0.8112781244591328\n",
      "[Temperature = medium]\n",
      "Probability = 0.4666666666666667\n",
      "Entropy = 0.9852281360342515\n",
      "\n",
      "Expected Entropy = 0.942780630005086\n",
      "\n",
      "INFORMATION GAIN = 0.02816996444958253\n",
      "------------------------------\n",
      "\n",
      "COLUMN = Humidity\n",
      "\n",
      "[Humidity = high]\n",
      "Probability = 0.5333333333333333\n",
      "Entropy = 0.9544340029249649\n",
      "[Humidity = normal]\n",
      "Probability = 0.4666666666666667\n",
      "Entropy = 0.5916727785823275\n",
      "\n",
      "Expected Entropy = 0.7851454315650674\n",
      "\n",
      "INFORMATION GAIN = 0.18580516288960114\n",
      "------------------------------\n",
      "\n",
      "COLUMN = Wind\n",
      "\n",
      "[Wind = strong]\n",
      "Probability = 0.4666666666666667\n",
      "Entropy = 0.9852281360342515\n",
      "[Wind = weak]\n",
      "Probability = 0.5333333333333333\n",
      "Entropy = 0.8112781244591328\n",
      "\n",
      "Expected Entropy = 0.8924547965275216\n",
      "\n",
      "INFORMATION GAIN = 0.078495797927147\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Root entropy\")\n",
    "root_ent = calculate_entropy(labels)\n",
    "print(\"Entropy = {}\".format(root_ent))\n",
    "print('-'*30)\n",
    "values[-1,0] = 'overcast'\n",
    "\n",
    "ees = np.zeros_like(cat_names, dtype=np.float64)\n",
    "for i in range(len(cat_names)):\n",
    "    x = values[:,i]\n",
    "    name = cat_names[i]\n",
    "    print(\"COLUMN = {}\".format(name))\n",
    "    print()\n",
    "    ee = calculate_expected_entropy(x, labels, name)\n",
    "    ees[i] = ee\n",
    "    print()\n",
    "    print(\"Expected Entropy = {}\".format(ee))\n",
    "    ig = root_ent - ee\n",
    "    print()\n",
    "    print(\"INFORMATION GAIN = {}\".format(ig))\n",
    "    print('-'*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(c)__. Fractional counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = values[:15,:]\n",
    "labels = labels[:15]\n",
    "\n",
    "fraction_values = values.copy()\n",
    "\n",
    "tot_count = values.shape[0]\n",
    "for i in range(len(cat_names)):\n",
    "    cats = set(values[:,i])\n",
    "    for c in cats:\n",
    "        match_indices = values[:, i] == c\n",
    "        fraction_values[match_indices, i] = np.count_nonzero(match_indices)/tot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root entropy\n",
      "Entropy = 0.9709505944546686\n",
      "------------------------------\n",
      "COLUMN = Outlook\n",
      "\n",
      "[Outlook = 0.3333333333333333]\n",
      "Probability = 1.0\n",
      "Entropy = 0.9709505944546686\n",
      "\n",
      "Expected Entropy = 0.9709505944546686\n",
      "\n",
      "INFORMATION GAIN = 0.0\n",
      "------------------------------\n",
      "\n",
      "COLUMN = Temperature\n",
      "\n",
      "[Temperature = 0.26666666666666666]\n",
      "Probability = 0.5333333333333333\n",
      "Entropy = 0.9544340029249649\n",
      "[Temperature = 0.4666666666666667]\n",
      "Probability = 0.4666666666666667\n",
      "Entropy = 0.9852281360342515\n",
      "\n",
      "Expected Entropy = 0.9688045983759652\n",
      "\n",
      "INFORMATION GAIN = 0.0021459960787033605\n",
      "------------------------------\n",
      "\n",
      "COLUMN = Humidity\n",
      "\n",
      "[Humidity = 0.5333333333333333]\n",
      "Probability = 0.5333333333333333\n",
      "Entropy = 0.9544340029249649\n",
      "[Humidity = 0.4666666666666667]\n",
      "Probability = 0.4666666666666667\n",
      "Entropy = 0.5916727785823275\n",
      "\n",
      "Expected Entropy = 0.7851454315650674\n",
      "\n",
      "INFORMATION GAIN = 0.18580516288960114\n",
      "------------------------------\n",
      "\n",
      "COLUMN = Wind\n",
      "\n",
      "[Wind = 0.5333333333333333]\n",
      "Probability = 0.5333333333333333\n",
      "Entropy = 0.8112781244591328\n",
      "[Wind = 0.4666666666666667]\n",
      "Probability = 0.4666666666666667\n",
      "Entropy = 0.9852281360342515\n",
      "\n",
      "Expected Entropy = 0.8924547965275216\n",
      "\n",
      "INFORMATION GAIN = 0.078495797927147\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Root entropy\")\n",
    "root_ent = calculate_entropy(labels)\n",
    "print(\"Entropy = {}\".format(root_ent))\n",
    "print('-'*30)\n",
    "values[-1,0] = 'overcast'\n",
    "\n",
    "ees = np.zeros_like(cat_names, dtype=np.float64)\n",
    "for i in range(len(cat_names)):\n",
    "    x = fraction_values[:,i]\n",
    "    name = cat_names[i]\n",
    "    print(\"COLUMN = {}\".format(name))\n",
    "    print()\n",
    "    ee = calculate_expected_entropy(x, labels, name)\n",
    "    ees[i] = ee\n",
    "    print()\n",
    "    print(\"Expected Entropy = {}\".format(ee))\n",
    "    ig = root_ent - ee\n",
    "    print()\n",
    "    print(\"INFORMATION GAIN = {}\".format(ig))\n",
    "    print('-'*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Programming Assignments\n",
    "\n",
    "\n",
    "__(a)__ See code\n",
    "\n",
    "__(b)__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          INFORMATION           \n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Tree Depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.703297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.777473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.803571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.848901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.916209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.916209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.916209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Train Accuracy  Test Accuracy\n",
       "Max Tree Depth                               \n",
       "1                        0.698       0.703297\n",
       "2                        0.778       0.777473\n",
       "3                        0.819       0.803571\n",
       "4                        0.918       0.848901\n",
       "5                        0.973       0.916209\n",
       "6                        1.000       0.916209\n",
       "7                        1.000       0.916209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            MAJORITY            \n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Tree Depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.703297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.777473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.865385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.918956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Train Accuracy  Test Accuracy\n",
       "Max Tree Depth                               \n",
       "1                        0.698       0.703297\n",
       "2                        0.778       0.777473\n",
       "3                        0.826       0.813187\n",
       "4                        0.909       0.865385\n",
       "5                        0.973       0.918956\n",
       "6                        1.000       0.918956\n",
       "7                        1.000       0.918956"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from id3 import ID3\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "train_data = train_df.values[:,:-1]\n",
    "train_labels = train_df.values[:,-1]\n",
    "test_data = test_df.values[:,:-1]\n",
    "test_labels = test_df.values[:,-1]\n",
    "names = train_df.columns[:-1]\n",
    "\n",
    "for split_mode in ['information', 'majority']:\n",
    "    split_table = np.zeros([7, 2]) \n",
    "    print()\n",
    "    print(split_mode.upper().center(32))\n",
    "    print(\"-\"*32)\n",
    "    #print(\"Tree depth || train acc || test acc\")\n",
    "    #print(\"-\"*11 + \"||\" + \"-\"*8 + \"||\")\n",
    "    for j in range(1,8):\n",
    "        id3 = ID3(split_mode=split_mode, max_depth=j)\n",
    "        id3.fit(train_data, train_labels, names)\n",
    "\n",
    "        train_count = 0\n",
    "        N = train_df.values.shape[0]\n",
    "        for i in range(N):\n",
    "            if id3.eval(train_data[i]) == train_labels[i]:\n",
    "                train_count += 1\n",
    "        split_table[j-1,0] = train_acc = train_count / N\n",
    "\n",
    "        test_count = 0\n",
    "        M = test_df.values.shape[0]\n",
    "        for i in range(M):\n",
    "            if id3.eval(test_data[i]) == test_labels[i]:\n",
    "                test_count += 1\n",
    "        split_table[j-1,1] = test_acc = test_count / M\n",
    "\n",
    "        #print(\"{}||{}||{}\".format(j, train_acc, test_acc))\n",
    "\n",
    "    df = pd.DataFrame(split_table, columns=['Train Accuracy', 'Test Accuracy'])\n",
    "    df.index += 1\n",
    "    df.index.name = 'Max Tree Depth'\n",
    "\n",
    "    from IPython.display import display\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(c)__ You can conclude that both models are overfitting to some extent.  They have high consistently higher training accuracies than test accuracies. Also, as was mentioned in class, the lower the allowed max depth, the less overfitting seems to occur.\n",
    "\n",
    "\n",
    "Also, the majority element version seems to have slightly higher performances on the test accuracy than information gain method, suggesting less overfitting. I found this interesting becuase I expected to the majority element version to perform worse, because it seems less principled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
